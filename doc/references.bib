@article{io_machine_learning_applications,
    author = {Lewis, Noah and Bez, Jean Luca and Byna, Suren},
    title = {I/O in Machine Learning Applications on HPC Systems: A 360-degree
             Survey},
    year = {2025},
    issue_date = {October 2025},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {57},
    number = {10},
    issn = {0360-0300},
    url = {https://doi.org/10.1145/3722215},
    doi = {10.1145/3722215},
    abstract = {Growing interest in Artificial Intelligence (AI) has resulted in
                a surge in demand for faster methods of Machine Learning (ML)
                model training and inference. This demand for speed has prompted
                the use of high performance computing (HPC) systems that excel in
                managing distributed workloads. Because data is the main fuel for
                AI applications, the performance of the storage and I/O subsystem
                of HPC systems is critical. In the past, HPC applications
                accessed large portions of data written by simulations or
                experiments or ingested data for visualizations or analysis
                tasks. ML workloads perform small reads spread across a large
                number of random files. This shift of I/O access patterns poses
                several challenges to modern parallel storage systems. In this
                article, we survey I/O in ML applications on HPC systems, and
                target literature within a 6-year time window from 2019 to 2024.
                We define the scope of the survey, provide an overview of the
                common phases of ML, review available profilers and benchmarks,
                examine the I/O patterns encountered during offline data
                preparation, training, and inference, and explore I/O
                optimizations utilized in modern ML frameworks and proposed in
                recent literature. Lastly, we seek to expose research gaps that
                could spawn further R&D.},
    journal = {ACM Comput. Surv.},
    month = may,
    articleno = {256},
    numpages = {41},
    keywords = {I/O access pattern, HPC I/O, storage, machine learning},
}
 
@inproceedings{dlio_benchmark,
    author = {Devarajan, Hariharan and Zheng, Huihuo and Kougkas, Anthony and
              Sun, Xian-He and Vishwanath, Venkatram},
    booktitle = {2021 IEEE/ACM 21st International Symposium on Cluster, Cloud
                 and Internet Computing (CCGrid)},
    title = {DLIO: A Data-Centric Benchmark for Scientific Deep Learning
             Applications},
    year = {2021},
    volume = {},
    number = {},
    pages = {81-91},
    keywords = {Deep learning;Training;Pipelines;Benchmark
                testing;Supercomputers;System software;Task analysis;deep
                learning;scientific applications;representative;benchmark;data
                intensive;I/O;characterization;Tensorflow;data pipeline},
    doi = {10.1109/CCGrid51090.2021.00018},
}


@inproceedings{analyzing_the_io_patterns,
    author = "P{\'a}rraga, Edixon and Le{\'o}n, Betzabeth and Bond, Rom{\'a}n
              and Encinas, Diego and Bezerra, Aprigio and Mendez, Sandra and
              Rexachs, Dolores and Luque, Emilio",
    editor = "Naiouf, Marcelo and Rucci, Enzo and Chichizola, Franco and De
              Giusti, Laura",
    title = "Analyzing the I/O Patterns of Deep Learning Applications",
    booktitle = "Cloud Computing, Big Data {\&} Emerging Topics",
    year = "2021",
    publisher = "Springer International Publishing",
    address = "Cham",
    pages = "3--16",
    abstract = "A traditional HPC storage system is designed to manage an I/O
                workload dominated by write operation bursts, mainly for
                applications carrying out simulations and checkpointing partial
                results. Currently, this context is more diverse because of
                artificial intelligence applications' workload, such as machine
                learning and deep learning. As ML/DL applications are becoming
                more compute-intensive, they require the power of HPC systems.
                However, the HPC I/O system could be a bottleneck to scaling
                these kind of applications, mainly in the training stage. In this
                paper, we present a methodology for analyzing the I/O patterns of
                deep learning applications that allows us to understand the DL
                applications' I/O in HPC systems. We have applied our approach to
                serial and distributed DL codes by using the TensorFlow2 and
                PyTorch framework for the MNIST and CIFAR-10 datasets.",
    isbn = "978-3-030-84825-5",
}

@inproceedings{understanding_and_leveraging_the_io_patterns_of_emerging_ml_analytics,
    author = "Gainaru, Ana and Ganyushin, Dmitry and Xie, Bing and Kurc, Tahsin
              and Saltz, Joel and Oral, Sarp and Podhorszki, Norbert and Poeschel
              , Franz and Huebl, Axel and Klasky, Scott",
    editor = "Nichols, Jeffrey and Maccabe, Arthur `Barney' and Nutaro, James
              and Pophale, Swaroop and Devineni, Pravallika and Ahearn, Theresa
              and Verastegui, Becky",
    title = "Understanding and Leveraging the I/O Patterns of Emerging Machine
             Learning Analytics",
    booktitle = "Driving Scientific and Engineering Discoveries Through the
                 Integration of Experiment, Big Data, and Modeling and Simulation
                 ",
    year = "2022",
    publisher = "Springer International Publishing",
    address = "Cham",
    pages = "119--138",
    abstract = "The scientific community is currently experiencing unprecedented
                amounts of data generated by cutting-edge science facilities.
                Soon facilities will be producing up to 1 PB/s which will force
                scientist to use more autonomous techniques to learn from the
                data. The adoption of machine learning methods, like deep
                learning techniques, in large-scale workflows comes with a shift
                in the workflow's computational and I/O patterns. These changes
                often include iterative processes and model architecture searches
                , in which datasets are analyzed multiple times in different
                formats with different model configurations in order to find
                accurate, reliable and efficient learning models. This shift in
                behavior brings changes in I/O patterns at the application level
                as well at the system level. These changes also bring new
                challenges for the HPC I/O teams, since these patterns contain
                more complex I/O workloads. In this paper we discuss the I/O
                patterns experienced by emerging analytical codes that rely on
                machine learning algorithms and highlight the challenges in
                designing efficient I/O transfers for such workflows. We comment
                on how to leverage the data access patterns in order to fetch in
                a more efficient way the required input data in the format and
                order given by the needs of the application and how to optimize
                the data path between collaborative processes. We will motivate
                our work and show performance gains with a study case of medical
                applications.",
    isbn = "978-3-030-96498-6",
}

@inproceedings{clairvoyant_prefetching_for_distributed_ml_io,
    author = {Dryden, Nikoli and B\"{o}hringer, Roman and Ben-Nun, Tal and
              Hoefler, Torsten},
    title = {Clairvoyant prefetching for distributed machine learning I/O},
    year = {2021},
    isbn = {9781450384421},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3458817.3476181},
    doi = {10.1145/3458817.3476181},
    abstract = {I/O is emerging as a major bottleneck for machine learning
                training, especially in distributed environments. Indeed, at
                large scale, I/O takes as much as 85\% of training time.
                Addressing this I/O bottleneck necessitates careful optimization,
                as optimal data ingestion pipelines differ between systems, and
                require a delicate balance between access to local storage,
                external filesystems, and remote nodes. We introduce NoPFS, a
                machine learning I/O middleware, which provides a scalable,
                flexible, and easy-to-use solution to the I/O bottleneck. NoPFS
                uses clairvoyance: Given the seed generating the random access
                pattern for training with SGD, it can exactly predict when and
                where a sample will be accessed. We combine this with an analysis
                of access patterns and a performance model to provide distributed
                caching policies that adapt to different datasets and storage
                hierarchies. NoPFS reduces I/O times and improves end-to-end
                training by up to 5.4\texttimes{} on the ImageNet-1k,
                ImageNet-22k, and CosmoFlow datasets.},
    booktitle = {Proceedings of the International Conference for High
                 Performance Computing, Networking, Storage and Analysis},
    articleno = {92},
    numpages = {15},
    keywords = {I/O, deep learning, high-performance computing},
    location = {St. Louis, Missouri},
    series = {SC '21},
}

@inproceedings{characterizing_ml_io_workloads,
    author = {Paul, Arnab K. and Karimi, Ahmad Maroof and Wang, Feiyi},
    booktitle = {2021 29th International Symposium on Modeling, Analysis, and
                 Simulation of Computer and Telecommunication Systems (MASCOTS)},
    title = {Characterizing Machine Learning I/O Workloads on Leadership Scale
             HPC Systems},
    year = {2021},
    volume = {},
    number = {},
    pages = {1-8},
    keywords = {Leadership;Analytical models;Systematics;File
                systems;Computational modeling;High performance
                computing;Tools;Burst Buffer;Darshan;High Performance
                Computing;HPC Storage;IBM Spectrum Scale;I/O
                Characterization;Machine Learning;Parallel File System},
    doi = {10.1109/MASCOTS53633.2021.9614303},
}
